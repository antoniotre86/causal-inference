{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Causal Inference with dowhy - simulated data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOE654JwdboNdBCqQq3qn5h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoniotre86/causal-inference/blob/main/notebooks/Causal_Inference_with_dowhy_simulated_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q5hPCH0zOe0"
      },
      "source": [
        "# Demo: Causal Inference with DoWhy - Simulated Data\n",
        "\n",
        "Demo on using [dowhy](https://github.com/microsoft/dowhy) for doing Causal Inference on some cooked up scenarios, to see its benefits and potential applications.\n",
        "\n",
        "***\n",
        "\n",
        "We simulate two scenarios based on a simplified version of the exercise / cholesterol example. \n",
        "\n",
        "* In **Scenario 1** we make *exercise* have a causal effect on *cholesterol*;\n",
        "* in **Scenario 2** *exercise* does not have a causal effect on *cholesterol*.\n",
        "\n",
        "We introduce a couple of confounding factors to make things interesting. We assume that these are the only confounding factors at play:\n",
        "* *occupation* (\"stormtrooper\" or \"radar technician\")\n",
        "* *age* in decades\n",
        "* *healthy diet*: binary, which depends on *Occupation*\n",
        "\n",
        "In both scenarios *exercise* and *cholesterol* are influenced by *age*, while *exercise* is influenced by *occupation* and *cholesterol* is influenced by *healthy diet* (and indirectly by *occupation* through it). \n",
        "\n",
        "We will see how *exercise* and *cholesterol* appear correlated in both scenarios, and with statistical significance. But using propensity score stratification we will be able to uncover the true causal effects. \n",
        "\n",
        "We will also apply the refutation methods to validate our results. \n",
        "\n",
        "---\n",
        "\n",
        "**Inference steps**:\n",
        "1. Define the causal graphical model\n",
        "2. Initialise the dowhy model by passing the training data and the graphical model in string dot format\n",
        "3. Run `.identify_estimand` for the dowhy model to identify the possible methods of inference (we will use \"backdoor.propensity_score_stratification\")\n",
        "4. Run `.estimate` to obtain the estimated causal effect\n",
        "5. Refute estimate by running built-in refutation methods.\n",
        "\n",
        "--- \n",
        "\n",
        "We are going to use [dowhy](https://github.com/microsoft/dowhy) which takes as input:\n",
        "- training data\n",
        "- causal graphical model (dot format)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NByb3YxB4ZV1"
      },
      "source": [
        "Install the required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J4IIRj1o9qR"
      },
      "source": [
        "!pip install dowhy\n",
        "!apt-get install graphviz\n",
        "!pip install graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMwzUtKdo_7B"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dowhy\n",
        "from dowhy import CausalModel\n",
        "from graphviz import Source\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(pd.__version__)\n",
        "print(np.__version__)\n",
        "print(dowhy.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkO9cSXzGOR-"
      },
      "source": [
        "pd.set_option(\"precision\", 3)\n",
        "sns.set()\n",
        "sns.set_palette(\"Accent\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Naj0IMLpFe-"
      },
      "source": [
        "# This prevents sklearn from printing a lot of warnings (copied from dowhy example notebooks)\n",
        "import warnings\n",
        "from sklearn.exceptions import DataConversionWarning, ConvergenceWarning\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
        "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
        "warnings.filterwarnings(action='ignore', category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk29u7a84nDD"
      },
      "source": [
        "## Define the graphical model\n",
        "\n",
        "One option is to define it as a string in dot format (really an option for small graphs only).\n",
        "\n",
        "Another option is to use [dagitty.net](http://www.dagitty.net/dags.html) -- allows you to create complex graphs by point-and-click. You can then export the textual version of it, which can be converted to dot fairly easily.\n",
        "\n",
        "We go for the first option here as the graph is simple enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTYcIiLs4yN7"
      },
      "source": [
        "graph_s = \"\"\"\n",
        "digraph {\n",
        "  exercise;\n",
        "  cholesterol;\n",
        "  age_years;\n",
        "  occupation;\n",
        "  healthy_diet;\n",
        "  age_years -> exercise;\n",
        "  age_years -> cholesterol;\n",
        "  occupation -> exercise;\n",
        "  occupation -> healthy_diet;\n",
        "  healthy_diet -> cholesterol;\n",
        "  exercise -> cholesterol;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "dag = Source(graph_s)\n",
        "\n",
        "dag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-JBpfLkpI6M"
      },
      "source": [
        "# Scenario 1: Exercise has a causal effect on Cholesterol level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0H12--UA9SE"
      },
      "source": [
        "## Generate the data\n",
        "\n",
        "We randomly generate *occupation* and *age_years* first as they don't depend on other variables. \n",
        "\n",
        "We then generate *exercise* based on *occupation* and *age* assuming that:\n",
        "- stormtroopers exercise more than radar technicians\n",
        "- people under 40 exercise more than people aged 40 or older\n",
        "\n",
        "We generate the *healty_diet* variable based on *occupation*, assuming radar technicians have a better diet.\n",
        "\n",
        "Finally, we generate *cholesterol* levels assuming that:\n",
        "- it's lower with an *healthy diet* and *exercise*\n",
        "- it's lower for people less than 40 years of *age*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWWmHgwHl1v4"
      },
      "source": [
        "np.random.seed(333)\n",
        "\n",
        "N = 1000\n",
        "\n",
        "data_s1 = pd.DataFrame(columns=[\"exercise\", \"cholesterol\", \"occupation\", \"age_years\", \"healthy_diet\"])\n",
        "\n",
        "data_s1[\"occupation\"] = np.random.choice([\"stormtrooper\", \"radar_technician\"], N)\n",
        "data_s1[\"age_years\"] = (np.random.normal(40, 10, N) / 10).astype(int) * 10\n",
        "\n",
        "# Stormtroopers get more exercise\n",
        "data_s1[\"exercise\"] = np.random.randn(N) \\\n",
        "  + 1*(data_s1[\"occupation\"] == \"stormtrooper\") \\\n",
        "  + -1*(data_s1[\"occupation\"] == \"radar_technician\")\n",
        "# People under 40 get more exercise\n",
        "data_s1[\"exercise\"] += 1*(data_s1[\"age_years\"] < 40)\n",
        "data_s1[\"exercise\"] = (data_s1[\"exercise\"] > data_s1[\"exercise\"].mean())\n",
        "\n",
        "\n",
        "# Stormtroopers have a poorer diet\n",
        "data_s1[\"healthy_diet\"] = np.random.rand(N) < (0.1*(data_s1[\"occupation\"] == \"stormtrooper\") \n",
        "                                              + 0.9*(data_s1[\"occupation\"] == \"radar_technician\"))\n",
        "\n",
        "# Base level of cholesterol (random)\n",
        "data_s1[\"cholesterol\"] = 5 + np.random.randn(N)**2 \n",
        "\n",
        "# A healthy diet gives lower cholesterol\n",
        "data_s1[\"cholesterol\"] += -3*data_s1[\"healthy_diet\"] \n",
        "\n",
        "# People under 40 have lower cholesterol\n",
        "data_s1[\"cholesterol\"] += -1*(data_s1[\"age_years\"] < 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5nSOekmnupo"
      },
      "source": [
        "# Exercise has the effect of reducing cholesterol\n",
        "actual_effect_s1 = -1\n",
        "data_s1[\"cholesterol\"] += actual_effect_s1*data_s1[\"exercise\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beumW_x7mDVe"
      },
      "source": [
        "data_s1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnt0hR1uDI3g"
      },
      "source": [
        "## Let's look at correlations first\n",
        "\n",
        "Between *occupation*, *exercise* and *cholesterol*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqHdwK3vnWhK"
      },
      "source": [
        "data_s1.groupby([\"occupation\", \"exercise\"])[\"cholesterol\"].mean().unstack(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNY2ZdaNDe51"
      },
      "source": [
        "As expected, *cholesterol* is the highest for stormtroopers who don't exercise, and the lowest for radar technicians who exercise.\n",
        "\n",
        "Let's add *age* as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu3MsWiMmDRb"
      },
      "source": [
        "data_s1.groupby([\"age_years\", \"occupation\", \"exercise\"])[\"cholesterol\"].mean().unstack([1,2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QENFW0iaDzd8"
      },
      "source": [
        "For most age levels, cholesterol is lower when they exercise, and in general it's also lower for radar technicians.\n",
        "\n",
        "Now we calculate the overall correlation coefficients:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9uF5dGrpgqg"
      },
      "source": [
        "data_s1.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kyy9hu8yEWPo"
      },
      "source": [
        "Most of these are expected, considering on how we generated the data. \n",
        "\n",
        "However, the correlation between cholesterol and exercise stands out. It looks like there is a POSITIVE correlation, meaning the more one exercise the higher their cholesterol levels!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7gV4ryBEIUH"
      },
      "source": [
        "data_s1.corr().loc[\"cholesterol\", \"exercise\"].round(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW0nR9xaNc9b"
      },
      "source": [
        "data_s1.groupby(\"exercise\")[\"cholesterol\"].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m13JB5jNjsc"
      },
      "source": [
        "observed_effect_s1 = data_s1.groupby(\"exercise\")[\"cholesterol\"].mean().diff().loc[True]\n",
        "observed_effect_s1.round(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX_GUonAEPwn"
      },
      "source": [
        "This appears to be an example of the [Simpson's Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox)\n",
        "\n",
        "> *Simpson's paradox, which also goes by several other names, is a phenomenon in probability and statistics in which a trend appears in several groups of data but disappears or reverses when the groups are combined.*\n",
        "\n",
        "In our example, cholesterol is lower for people who exercise if we break down the data by occupation and age, but it appears to be positively correlated with exercise if we look at the data in aggregate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uWzdrz4pt5p"
      },
      "source": [
        "ttest_ind(data_s1.loc[data_s1[\"exercise\"], \"cholesterol\"].values, data_s1.loc[~data_s1[\"exercise\"], \"cholesterol\"].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Arslj4TUFCmE"
      },
      "source": [
        "A t-test confirms that the correlation is also statistically significant with p-value < 0.001."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icdQOtdTF2Qm"
      },
      "source": [
        "## Causal Inference\n",
        "\n",
        "We now turn to Causal Inference to hopefully find the true causal effect between exercise and cholesterol. \n",
        "\n",
        "We are going to use [dowhy]() for the task, and use [Propensity Score Matching](https://en.wikipedia.org/wiki/Propensity_score_matching) (with stratification) to estimate the actual causal effect. \n",
        "\n",
        "***\n",
        "\n",
        "We first instantiate the model and pass our data, the treatment and outcome names, and the graph in dot format.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gge8E997mDNX"
      },
      "source": [
        "model_s1 = CausalModel(\n",
        "        data=data_s1,\n",
        "        treatment=\"exercise\",\n",
        "        outcome=\"cholesterol\",\n",
        "        graph=graph_s.replace('\\n', '').strip()\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7t1kEKNHrSK"
      },
      "source": [
        "Next, we run the actual estimation method.\n",
        "\n",
        "`.identify_effect` parses the graph and defines the estimands.\n",
        "\n",
        "`.estimate_effect` with \"backdoor.propensity_score_stratification\" as `method_name` runs the propensity score model and returns the estimated effect.\n",
        "\n",
        "Here we can also define \n",
        "- specific method parameters in `method_params`; for PS stratification we can define the number of strata and how many items of one class required in each stratum as a minumum (otherwise the stratum is dropped);\n",
        "- whether we want a confidence interval around the estimate, and the method to compute it; in this case we decided to calculate it with bootstrapping;\n",
        "- whether we want to test for statistical significance (not recommended if you are calculating the confidence interval already as it will just slow down the estimation -- we can judge significance at the 95% level from the confidence interval already). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ9LLhPeHsDb"
      },
      "source": [
        "# Identify causal effect and return target estimands\n",
        "identified_estimand = model_s1.identify_effect(proceed_when_unidentifiable=True)\n",
        "\n",
        "# Estimate the target estimand using a statistical method. Propensity score stratification.\n",
        "estimate_s1 = model_s1.estimate_effect(identified_estimand,\n",
        "                                  method_name=\"backdoor.propensity_score_stratification\",\n",
        "                                  target_units=\"ate\",\n",
        "                                  confidence_intervals='bootstrap',\n",
        "                                  test_significance=False,\n",
        "                                  method_params={\"num_strata\":20, \"clipping_threshold\":5, \"num_simulations\":100})\n",
        "\n",
        "estimated_effect_s1 = estimate_s1.value\n",
        "estimated_effect_c1_s1 = estimate_s1.get_confidence_intervals()\n",
        "\n",
        "print(f\"Estimated causal effect: {estimated_effect_s1:0.3g}; \"\n",
        "  f\"95% conf. int.: ({estimated_effect_c1_s1[0]:0.3g}, {estimated_effect_c1_s1[1]:0.3g})\")\n",
        "print(f\"Actual causal effect: {actual_effect_s1}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaWWSsHeNXov"
      },
      "source": [
        "The estimated causal effect is correclty negative and close to the actual effect we defined when simulating the data (it's contained in the estimate confidence interval). \n",
        "\n",
        "What we would have thought being a positive relationship between exercise and cholesterol (more exercise - higher cholesterol), is in reality a negative one; the positive correlation we had observed was entirely due to the effect of the confounding factors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU6mPgiMbkgV"
      },
      "source": [
        "## Refutation\n",
        "\n",
        "We will now see if we can refute the estimates (even though it's not necessary in this case as we have generated the data ourselves based on a pre-defined causal model).\n",
        "\n",
        "Dowhy provides a collection of refutation methods to use. We will use three of them:\n",
        "- adding a random confounder\n",
        "- replacing treatment with a placebo\n",
        "- re-running the estimate on data subsets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cedo4-BPbkgW"
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "refute_results_0 = model_s1.refute_estimate(identified_estimand, \n",
        "                                          estimate_s1, \n",
        "                                          method_name=\"random_common_cause\", \n",
        "                                          confounders_effect_on_treatment=\"binary_flip\", \n",
        "                                          confounders_effect_on_outcome=\"binary_flip\")\n",
        "print(refute_results_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_FpmaVUbkgW"
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "refute_results_1 = model_s1.refute_estimate(identified_estimand, \n",
        "                                         estimate_s1, \n",
        "                                         method_name=\"placebo_treatment_refuter\", \n",
        "                                         placebo_type=\"Random Data\", \n",
        "                                         num_simulations=10)\n",
        "\n",
        "print(refute_results_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtaMkRQdbkgW"
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "refute_results_2 = model_s1.refute_estimate(identified_estimand, \n",
        "                                         estimate_s1, \n",
        "                                         method_name=\"data_subset_refuter\", \n",
        "                                         subset_fraction=0.5, \n",
        "                                         num_simulations=10)\n",
        "\n",
        "print(refute_results_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omtWXc1ybkgX"
      },
      "source": [
        "The three refutation methods used return the expected results:\n",
        "- adding a randomly drawn confounder does not significantly change the estimate\n",
        "- replacing the treatment with a randomly shuffled one makes the effect go to zero\n",
        "- re-running the estimates on several subsamples of the data returns a similar estimate as the original one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daVe1kmRtIr8"
      },
      "source": [
        "# Scenario 2: Exercise does not have an impact on Cholesterol level\n",
        "\n",
        "Let's now see what happens if we generate the data such that there is no direct causal effect between exercise and cholesterol."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXv4VOTqtIKx"
      },
      "source": [
        "np.random.seed(333)\n",
        "\n",
        "N = 1000\n",
        "\n",
        "data_s2 = data_s1.copy()\n",
        "\n",
        "# Base level of cholesterol (random)\n",
        "data_s2[\"cholesterol\"] = 5 + np.random.randn(N)**2 \n",
        "\n",
        "# A healthy diet gives lower cholesterol\n",
        "data_s2[\"cholesterol\"] += -3*data_s2[\"healthy_diet\"] \n",
        "\n",
        "# People under 40 have lower cholesterol\n",
        "data_s2[\"cholesterol\"] += -1*(data_s2[\"age_years\"] < 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xes1avk1nzib"
      },
      "source": [
        "# Exercise does not affect cholesterol\n",
        "actual_effect_s2 = 0.0\n",
        "data_s2[\"cholesterol\"] += actual_effect_s2*data_s2[\"exercise\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfrQVz2YPuXP"
      },
      "source": [
        "## Let's look at correlations first\n",
        "\n",
        "Between *occupation*, *exercise* and *cholesterol*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrrgLFzFPuXP"
      },
      "source": [
        "data_s2.groupby([\"occupation\", \"exercise\"])[\"cholesterol\"].mean().unstack(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6v1qJTvPuXP"
      },
      "source": [
        "Like before, *cholesterol* is the highest for stormtroopers who don't exercise, and the lowest for radar technicians who exercise.\n",
        "\n",
        "Let's add *age* as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYwZ13qqPuXQ"
      },
      "source": [
        "data_s2.groupby([\"age_years\", \"occupation\", \"exercise\"])[\"cholesterol\"].mean().unstack([1,2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mccpiBn5PuXQ"
      },
      "source": [
        "Cholesterol is still higher with older age, but now we don't see a correlation with exercise in the individual age groups.\n",
        "\n",
        "Now we calculate the overall correlation coefficients:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SYvNaUqPuXQ"
      },
      "source": [
        "data_s2.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj9R-oykPuXQ"
      },
      "source": [
        "However, now cholesterol and exercise appear even more positively correlated!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmNuiGFAPuXQ"
      },
      "source": [
        "data_s2.corr().loc[\"cholesterol\", \"exercise\"].round(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHCCGmIKPuXR"
      },
      "source": [
        "data_s2.groupby(\"exercise\")[\"cholesterol\"].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFKbj9JqPuXR"
      },
      "source": [
        "observed_effect_s2 = data_s2.groupby(\"exercise\")[\"cholesterol\"].mean().diff().loc[True]\n",
        "observed_effect_s2.round(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2xH4lrePuXR"
      },
      "source": [
        "ttest_ind(data_s2.loc[data_s2[\"exercise\"], \"cholesterol\"].values, data_s2.loc[~data_s1[\"exercise\"], \"cholesterol\"].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkICOc1MPuXR"
      },
      "source": [
        "A t-test confirms that the correlation is also statistically significant with p-value < 0.001."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdJqba--PuXS"
      },
      "source": [
        "## Causal Inference\n",
        "\n",
        "Let's use propensity score matching like before to see if it's able to estimate the real causal effect between exercise and cholesterol in this scenario (should be close to 0). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBZpXZwuPuXS"
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "model_s2 = CausalModel(\n",
        "    data=data_s2,\n",
        "    treatment=\"exercise\",\n",
        "    outcome=\"cholesterol\",\n",
        "    graph=graph_s.replace('\\n', '').strip()\n",
        ")\n",
        "\n",
        "# Identify causal effect and return target estimands\n",
        "identified_estimand = model_s2.identify_effect(proceed_when_unidentifiable=True)\n",
        "\n",
        "# Estimate the target estimand using a statistical method. Propensity score stratification.\n",
        "estimate_s2 = model_s2.estimate_effect(identified_estimand,\n",
        "                                    method_name=\"backdoor.propensity_score_stratification\",\n",
        "                                    target_units=\"ate\",\n",
        "                                    test_significance=False,\n",
        "                                    confidence_intervals='bootstrap',\n",
        "                                    method_params={\"num_strata\":20, \"clipping_threshold\":5, \"num_simulations\":100})\n",
        "\n",
        "estimated_effect_s2 = estimate_s2.value\n",
        "estimated_effect_c1_s2 = estimate_s2.get_confidence_intervals()\n",
        "\n",
        "print(f\"Estimated causal effect: {estimated_effect_s2:0.3g}; \"\n",
        "  f\"95% conf. int.: ({estimated_effect_c1_s2[0]:0.3g}, {estimated_effect_c1_s2[1]:0.3g})\")\n",
        "print(f\"Actual causal effect: {actual_effect_s2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6J9y41gPuXT"
      },
      "source": [
        "Indeed, the estimated causal effect is correclty close to zero (confirmed also by the confidence interval including zero).\n",
        "\n",
        "Again, what we would have thought being a positive relationship between exercise and cholesterol (and this time even a stronger one than in the first scenario), does not exist in reality; the positive correlation we had observed was entirely due to the effect of the confounding factors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCbot4xdBxt6"
      },
      "source": [
        "# Analysis of Propensity Score model (back to Scenario 1)\n",
        "\n",
        "We can look into how the propensity score model is performing in the background."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQmAKZpgDc2B"
      },
      "source": [
        "treatment_name = \"exercise\"\n",
        "outcome_name = \"cholesterol\"\n",
        "\n",
        "model = model_s1\n",
        "estimate = estimate_s1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4hUEiuUaRSr"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "ax.set_title(\"Distribution of propensity scores\")\n",
        "ax.set_xlabel(\"Propensity score\")\n",
        "df_ = pd.DataFrame({\"p\": estimate.propensity_scores, treatment_name:data_s1[treatment_name]})\n",
        "for t in df_[treatment_name].unique():\n",
        "    sns.kdeplot(df_.loc[df_[treatment_name] == t, \"p\"], ax=ax, label=f\"{treatment_name}={t}\", clip=(0,1))\n",
        "ax.set_xlim(0,1)\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w2rZijPDlHo"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "ax.set_title(\"Distribution of estimated ATE\")\n",
        "ax.set_xlabel(\"ATE estimate\")\n",
        "ax.hist(estimate.estimator._bootstrap_estimates.estimates, bins=20, density=True)\n",
        "sns.kdeplot(estimate.estimator._bootstrap_estimates.estimates, ax=ax, color='lightblue')\n",
        "cil, cih = estimate.get_confidence_intervals()\n",
        "ax.axvline(estimate.value, color='slategrey')\n",
        "ax.axvline(cil, linestyle='dashed', color='slategrey')\n",
        "ax.axvline(cih, linestyle='dashed', color='slategrey')\n",
        "ymin, ymax = ax.get_ylim()\n",
        "ax.text(estimate.value, ymax, f\" mean: {estimate.value:0.3f}\", color='slategrey', va='top', size=9)\n",
        "ax.text(cil, ymax, f\" CI-L: {cil:0.3f}\", color='slategrey', va='top', size=9)\n",
        "ax.text(cih, ymax, f\" CI-H: {cih:0.3f}\", color='slategrey', va='top', size=9)\n",
        "# Plot x=0 line if x=0 in view already\n",
        "xmin, xmax = ax.get_xlim()\n",
        "if np.sign(xmin*xmax) == -1:\n",
        "    ax.axvline(0, color='firebrick')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kKUn4sxDs-M"
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(data_s1[treatment_name].values*1, estimate.propensity_scores, pos_label=1)\n",
        "roc_score = roc_auc_score(data_s1[treatment_name].values*1, estimate.propensity_scores)\n",
        "ax.plot(fpr, tpr, '-.')\n",
        "ax.plot([0, 1], [0, 1], 'r--')\n",
        "ax.text(0.8, 0.2, f\"AUC={roc_score:.3f}\", ha='center', color='slategrey')\n",
        "ax.set_xlabel(\"FPR\")\n",
        "ax.set_ylabel(\"TPR\")\n",
        "ax.set_title(f\"Propensity score estimator ROC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sun_2T7ZD2BZ"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "p, r, _ = precision_recall_curve(data_s1[treatment_name].values*1, estimate.propensity_scores, pos_label=1)\n",
        "ax.plot(p, r, '-.')\n",
        "ax.set_xlabel(\"Precision\")\n",
        "ax.set_ylabel(\"Recall\")\n",
        "ax.set_title(f\"Propensity score estimator P/R curve\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLof0XRnD7yA"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "coef_ = estimate.estimator._propensity_score_model.coef_[0]\n",
        "coef_weights = (estimate.estimator._observed_common_causes.mean().T / estimate.estimator._observed_common_causes.mean().sum()).values\n",
        "fnames = estimate.estimator._observed_common_causes.columns\n",
        "ax = pd.DataFrame({'coef_weighted':coef_/coef_weights}, index=fnames).sort_values('coef_weighted')\\\n",
        "    .plot(kind='barh', legend=False, ax=ax)\n",
        "ax.set_title('Propensity score estimator feature importance')\n",
        "ax.set_xlabel('Feature importance')\n",
        "ax.set_ylabel('Propensity model feature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66GPE0FAEWzP"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "\n",
        "\n",
        "def _strata_counts(df, treatment_name):\n",
        "    df_strata_counts_1 = df.groupby(['strata', treatment_name])[treatment_name].count().unstack(1).reset_index()\n",
        "    df_strata_counts_1.columns = ['stratum'] + [f\"{o}\" for o in df[treatment_name].unique()]\n",
        "    df_strata_counts_2 = df_strata_counts_1.set_index('stratum').stack().reset_index()\n",
        "    df_strata_counts_2.columns = ['stratum', treatment_name, 'count']\n",
        "    df_strata_counts_2['stratum'] = df_strata_counts_2['stratum'].astype(int)\n",
        "\n",
        "    return df_strata_counts_2\n",
        "\n",
        "\n",
        "def _effect_per_strata(df, treatment_name):\n",
        "    df_strata_effect_1 = df_.groupby('strata').agg({\n",
        "                    treatment_name: ['sum'],\n",
        "                    'dbar': ['sum'],\n",
        "                    'd_y': ['sum'],\n",
        "                    'dbar_y': ['sum']\n",
        "                }).reset_index().rename(columns={'strata':'stratum'}).set_index('stratum')\n",
        "    df_strata_effect_1.columns = [\"_\".join(x) for x in df_strata_effect_1.columns.ravel()]\n",
        "    treatment_sum_name = treatment_name + \"_sum\"\n",
        "    control_sum_name = \"dbar_sum\"\n",
        "    df_strata_effect_1['d_y_mean'] = df_strata_effect_1['d_y_sum'] / df_strata_effect_1[treatment_sum_name]\n",
        "    df_strata_effect_1['dbar_y_mean'] = df_strata_effect_1['dbar_y_sum'] / df_strata_effect_1['dbar_sum']\n",
        "    df_strata_effect_1['effect'] = df_strata_effect_1['d_y_mean'] - df_strata_effect_1['dbar_y_mean']\n",
        "    df_strata_effect_1 = df_strata_effect_1['effect'].reset_index()\n",
        "\n",
        "    return df_strata_effect_1\n",
        "\n",
        "\n",
        "df_ = estimate.estimator._data\n",
        "df_strata_counts = _strata_counts(df_, treatment_name)\n",
        "df_strata_effect = _effect_per_strata(df_, treatment_name)\n",
        "\n",
        "sns.barplot(x='stratum', y='count', data=df_strata_counts, hue=treatment_name, ax=ax)\n",
        "ax_secondary = ax.twinx()\n",
        "ax_secondary.set_ylabel('effect')\n",
        "df_strata_effect['effect'].plot(ax=ax_secondary, grid=False, linewidth=2, color='gold', marker='*', label='effect')\n",
        "l_scale = lambda x, factor: x*(1+np.sign(x)*factor)\n",
        "ax_secondary.set_ylim(None, l_scale(ax_secondary.get_ylim()[1], .3))\n",
        "\n",
        "ax.set_title('Propensity score stratification - strata counts and effects')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgRUdo0bEtD0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}